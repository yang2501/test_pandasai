{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may need to run \"pip install -r requirements.txt\" to install dependencies\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import ClientSecretCredential\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from pandasai.smart_dataframe import SmartDataframe\n",
    "from pandasai import Agent\n",
    "import pandas as pd\n",
    "from langchain_openai.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AzureOpenAISetup:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        self.tenant_id = os.environ.get(\"tenant_id\")\n",
    "        self.client_id = os.environ.get(\"client_id\")\n",
    "        self.client_secret = os.environ.get(\"client_secret\")\n",
    "        self.refresh_token()\n",
    "\n",
    "    def refresh_token(self):\n",
    "        credential = ClientSecretCredential(\n",
    "            self.tenant_id, self.client_id, self.client_secret)\n",
    "        self.token = credential.get_token(\n",
    "            \"https://cognitiveservices.azure.com/.default\")\n",
    "        os.environ[\"OPENAI_API_TYPE\"] = \"azure_ad\"\n",
    "        os.environ[\"OPENAI_API_KEY\"] = self.token.token\n",
    "        os.environ[\"AZURE_OPENAI_AD_TOKEN\"] = self.token.token\n",
    "        os.environ[\"OPENAI_API_VERSION\"] = \"2023-07-01-preview\"\n",
    "\n",
    "        self.embeddings = AzureOpenAIEmbeddings(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            openai_api_key=self.token.token,\n",
    "            azure_endpoint=\"https://do-openai-instance.openai.azure.com/\",\n",
    "        )\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        return self.embeddings\n",
    "\n",
    "    def get_token(self):\n",
    "        return self.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_name = 'gpt-4-32k'\n",
    "azure_endpoint=\"https://do-openai-instance.openai.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_setup = AzureOpenAISetup()\n",
    "# refresh token and update corresponding envs\n",
    "# call this refresh_token if needed\n",
    "azure_setup.refresh_token()\n",
    "\n",
    "# create llm from Azure OpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    streaming=False,\n",
    "    deployment_name=llm_model_name,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure PandasAI\n",
    "# see config section at \"https://docs.pandas-ai.com/getting-started\" for available options\n",
    "config = {\n",
    "    \"llm\": llm,\n",
    "    # Other configuration options as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./data/standardized_analysis_ready_df.csv\")\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# unique_visits_df = df['VISIT'].drop_duplicates()\n",
    "# print(unique_visits_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"(true | false)\"\n",
    "from pandasai.ee.vectorstores import ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the vector store\n",
    "vector_store = ChromaDB()\n",
    "description = \"You're a data engineer. You're very good at processing and transforming data before calling the custom skills.\"\n",
    "config={\"llm\": llm}\n",
    "\n",
    "description = \"You're a data analyst.\"\n",
    "\n",
    "agent = Agent(df, vectorstore=vector_store, config=config, description=description)\n",
    "agent.chat('How many devices are there?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unique Counts</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Summary Stats</th>\n",
       "      <th>Missing Values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>USUBJID</th>\n",
       "      <th>digital_EP_value</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VISIT</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USUBJID</th>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digital_EP</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digital_EP_value</th>\n",
       "      <td>6131.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digital_EP_severity_category</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COHORT</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEVICE</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33267.000000</td>\n",
       "      <td>33235.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10225.849701</td>\n",
       "      <td>80.407287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>135.816825</td>\n",
       "      <td>120.475050</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10107.000000</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10235.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10346.000000</td>\n",
       "      <td>82.045500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10458.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Unique Counts Summary Stats                   \\\n",
       "                                         0       USUBJID digital_EP_value   \n",
       "VISIT                                 10.0           NaN              NaN   \n",
       "USUBJID                              360.0           NaN              NaN   \n",
       "digital_EP                            22.0           NaN              NaN   \n",
       "digital_EP_value                    6131.0           NaN              NaN   \n",
       "digital_EP_severity_category           4.0           NaN              NaN   \n",
       "COHORT                                 3.0           NaN              NaN   \n",
       "DEVICE                                 2.0           NaN              NaN   \n",
       "count                                  NaN  33267.000000     33235.000000   \n",
       "mean                                   NaN  10225.849701        80.407287   \n",
       "std                                    NaN    135.816825       120.475050   \n",
       "min                                    NaN  10001.000000         0.000000   \n",
       "25%                                    NaN  10107.000000         8.950000   \n",
       "50%                                    NaN  10235.000000        33.000000   \n",
       "75%                                    NaN  10346.000000        82.045500   \n",
       "max                                    NaN  10458.000000       480.000000   \n",
       "\n",
       "                             Missing Values  \n",
       "                                          1  \n",
       "VISIT                                   0.0  \n",
       "USUBJID                                 0.0  \n",
       "digital_EP                              0.0  \n",
       "digital_EP_value                       32.0  \n",
       "digital_EP_severity_category        31206.0  \n",
       "COHORT                                  0.0  \n",
       "DEVICE                                  0.0  \n",
       "count                                   NaN  \n",
       "mean                                    NaN  \n",
       "std                                     NaN  \n",
       "min                                     NaN  \n",
       "25%                                     NaN  \n",
       "50%                                     NaN  \n",
       "75%                                     NaN  \n",
       "max                                     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.chat('Summarize the important findings from the data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasai.skills import skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VISIT</th>\n",
       "      <th>USUBJID</th>\n",
       "      <th>digital_EP</th>\n",
       "      <th>digital_EP_value</th>\n",
       "      <th>digital_EP_severity_category</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>DEVICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Screening</td>\n",
       "      <td>10002</td>\n",
       "      <td>TIB</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>PSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Screening</td>\n",
       "      <td>10003</td>\n",
       "      <td>TIB</td>\n",
       "      <td>395.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>PSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Screening</td>\n",
       "      <td>10001</td>\n",
       "      <td>TIB</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Screening</td>\n",
       "      <td>10006</td>\n",
       "      <td>TIB</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Screening</td>\n",
       "      <td>10007</td>\n",
       "      <td>TIB</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PSG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VISIT  USUBJID digital_EP  digital_EP_value  \\\n",
       "0  Screening    10002        TIB             480.0   \n",
       "1  Screening    10003        TIB             395.5   \n",
       "2  Screening    10001        TIB             480.0   \n",
       "3  Screening    10006        TIB             450.0   \n",
       "4  Screening    10007        TIB             480.0   \n",
       "\n",
       "  digital_EP_severity_category   COHORT DEVICE  \n",
       "0                          NaN  Placebo    PSG  \n",
       "1                          NaN  Placebo    PSG  \n",
       "2                          NaN  Unknown    PSG  \n",
       "3                          NaN  Unknown    PSG  \n",
       "4                          NaN  Unknown    PSG  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Plot bland_altman to compare device/ endpoint alignment\n",
    "\n",
    "@skill\n",
    "def bland_altman_plot(df, endpoint1, endpoint2, device1=None, device2=None, bySeverityCategory=False):\n",
    "    \"\"\"\n",
    "    Generates a Bland-Altman plot to compare two devices or two endpoints, optionally by severity category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The original DataFrame containing the data.\n",
    "            'VISIT': Visit name (e.g. VISIT2)\n",
    "            'USUBJID': Unique subject ID\n",
    "            'digital_EP': Endpoint name (e.g. WASO, AHI, etc.)\n",
    "            'digital_EP_value': Endpoint value (some numeric value)\n",
    "            'digital_EP_severity_category': Severity category of the endpoint\n",
    "            'COHORT': Treatment group (e.g. Placebo/ Treatment)\n",
    "            'DEVICE': Device name (e.g. WatchPAT, PSG, etc.)\n",
    "    endpoint1 : str\n",
    "        The first endpoint to compare (e.g., WASO).\n",
    "    endpoint2 : str\n",
    "        The second endpoint to compare (e.g., AHI).\n",
    "    device1 : str, optional\n",
    "        The first device to compare (e.g., WatchPAT).\n",
    "    device2 : str, optional\n",
    "        The second device to compare (e.g., PSG).\n",
    "    bySeverityCategory : bool, optional\n",
    "        Whether to plot the Bland-Altman plots by severity category.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    str\n",
    "        Confirmation message after plotting.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    if endpoint1 == endpoint2:\n",
    "        # Filter the DataFrame for the specified endpoint and devices\n",
    "        \n",
    "        df1 = df[(df['digital_EP'] == endpoint1) & (df['DEVICE'] == device1)][['USUBJID', 'VISIT', 'digital_EP_value', 'digital_EP_severity_category']].rename(columns={'digital_EP_value': f'digital_EP_value_{device1}'})\n",
    "        df2 = df[(df['digital_EP'] == endpoint1) & (df['DEVICE'] == device2)][['USUBJID', 'VISIT', 'digital_EP_value', 'digital_EP_severity_category']].rename(columns={'digital_EP_value': f'digital_EP_value_{device2}'})\n",
    "    else:\n",
    "        # Filter the DataFrame for the specified endpoints\n",
    "        df1 = df[(df['digital_EP'] == endpoint1)][['USUBJID', 'VISIT', 'digital_EP_value', 'digital_EP_severity_category']].rename(columns={'digital_EP_value': f'{endpoint1}_value'})\n",
    "        df2 = df[(df['digital_EP'] == endpoint2)][['USUBJID', 'VISIT', 'digital_EP_value', 'digital_EP_severity_category']].rename(columns={'digital_EP_value': f'{endpoint2}_value'})\n",
    "\n",
    "    # Merge the two DataFrames on the subject ID and visit\n",
    "    df_merged = pd.merge(df1, df2, on=['USUBJID', 'VISIT', 'digital_EP_severity_category'])\n",
    "\n",
    "    # Check if there is data to plot\n",
    "    if df_merged.empty:\n",
    "        print(\"No overlapping data between the specified endpoints/devices. Please specify valid endpoints to compare. If there is one endpoint, please specify the devices to compare. You can also specify whether to plot by severity category.\")\n",
    "        return \"error\"\n",
    "\n",
    "    if bySeverityCategory:\n",
    "        # Get the unique severity categories\n",
    "        severity_categories = df_merged['digital_EP_severity_category'].unique()\n",
    "\n",
    "        # Create a plot for each severity category\n",
    "        for category in severity_categories:\n",
    "            category_data = df_merged[df_merged['digital_EP_severity_category'] == category]\n",
    "\n",
    "            # Calculate the mean and difference of the two endpoints\n",
    "            if endpoint1 == endpoint2:\n",
    "                category_data['mean'] = category_data[[f'digital_EP_value_{device1}', f'digital_EP_value_{device2}']].mean(axis=1)\n",
    "                category_data['difference'] = category_data[f'digital_EP_value_{device1}'] - category_data[f'digital_EP_value_{device2}']\n",
    "            else:\n",
    "                category_data['mean'] = category_data[[f'{endpoint1}_value', f'{endpoint2}_value']].mean(axis=1)\n",
    "                category_data['difference'] = category_data[f'{endpoint1}_value'] - category_data[f'{endpoint2}_value']\n",
    "\n",
    "            # Calculate the mean difference and limits of agreement\n",
    "            mean_diff = category_data['difference'].mean()\n",
    "            std_diff = category_data['difference'].std()\n",
    "            upper_limit = mean_diff + 1.96 * std_diff\n",
    "            lower_limit = mean_diff - 1.96 * std_diff\n",
    "            count = len(category_data['difference'])\n",
    "\n",
    "            # Create the Bland-Altman plot\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(category_data['mean'], category_data['difference'], alpha=0.5)\n",
    "            plt.axhline(mean_diff, color='gray', linestyle='solid', label=f'Mean Difference: {mean_diff:.2f}')\n",
    "            plt.axhline(upper_limit, color='red', linestyle='--', label=f'+1.96 SD: {upper_limit:.2f}')\n",
    "            plt.axhline(lower_limit, color='red', linestyle='--', label=f'-1.96 SD: {lower_limit:.2f}')\n",
    "            plt.xlabel('Means')\n",
    "            plt.ylabel(f'Difference: {endpoint1} - {endpoint2}' if endpoint1 != endpoint2 else f'Difference: {endpoint1} ({device1}) - {endpoint1} ({device2})')\n",
    "            plt.title(f'Bland-Altman Plot for {count} {endpoint1} - {endpoint2} pairs\\nSeverity Category: {category}' if endpoint1 != endpoint2 else f'Bland-Altman Plot for {count} {device1} - {device2} pairs\\nSeverity Category: {category}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        # Calculate the mean and difference of the two endpoints\n",
    "        if endpoint1 == endpoint2:\n",
    "            df_merged['mean'] = df_merged[[f'digital_EP_value_{device1}', f'digital_EP_value_{device2}']].mean(axis=1)\n",
    "            df_merged['difference'] = df_merged[f'digital_EP_value_{device1}'] - df_merged[f'digital_EP_value_{device2}']\n",
    "        else:\n",
    "            df_merged['mean'] = df_merged[[f'{endpoint1}_value', f'{endpoint2}_value']].mean(axis=1)\n",
    "            df_merged['difference'] = df_merged[f'{endpoint1}_value'] - df_merged[f'{endpoint2}_value']\n",
    "\n",
    "        # Calculate the mean difference and limits of agreement\n",
    "        mean_diff = df_merged['difference'].mean()\n",
    "        std_diff = df_merged['difference'].std()\n",
    "        upper_limit = mean_diff + 1.96 * std_diff\n",
    "        lower_limit = mean_diff - 1.96 * std_diff\n",
    "        count = len(df_merged['difference'])\n",
    "\n",
    "        # Create the Bland-Altman plot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(df_merged['mean'], df_merged['difference'], alpha=0.5)\n",
    "        plt.axhline(mean_diff, color='gray', linestyle='solid', label=f'Mean Difference: {mean_diff:.2f}')\n",
    "        plt.axhline(upper_limit, color='red', linestyle='--', label=f'+1.96 SD: {upper_limit:.2f}')\n",
    "        plt.axhline(lower_limit, color='red', linestyle='--', label=f'-1.96 SD: {lower_limit:.2f}')\n",
    "        plt.xlabel('Means')\n",
    "        plt.ylabel(f'Difference: {endpoint1} - {endpoint2}' if endpoint1 != endpoint2 else f'Difference: {endpoint1} ({device1}) - {endpoint1} ({device2})')\n",
    "        plt.title(f'Bland-Altman Plot for {count} {endpoint1} - {endpoint2} pairs' if endpoint1 != endpoint2 else f'Bland-Altman Plot: for {count} {device1} - {device2} pairs')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return \"success\"\n",
    "\n",
    "# Plot change from baseline. By default, if no device is specified, it plots the change from baseline for an endpoint for all devices.\n",
    "\n",
    "@skill\n",
    "def change_from_baseline_plot(df, endpoint, device=None):\n",
    "    \"\"\"\n",
    "    Plots a change from baseline chart for different cohorts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The original DataFrame containing the data.\n",
    "            'VISIT' (e.g. VISIT3). The get_visit_number() function relies on screening visit being marked as 'Screening'. The data should be cleaned such that there are only valid visits in this column\n",
    "            'USUBJID': unique subject ID\n",
    "            'digital_EP': (e.g. WASO, AHI, etc.)\n",
    "            'digital_EP_value': (some numeric value)\n",
    "            'digital_EP_severity_category' \n",
    "            'COHORT' (e.g. Placebo/ Treatment)\n",
    "            'DEVICE' (WatchPAT, PSG, etc.)\n",
    "    endpoint : str\n",
    "        The Digital_EP to plot (e.g., WASO, AHI, etc.). If the endpoint is not provided. Ask the user a clarifying question for the endpoint.\n",
    "    device : str, optional\n",
    "        The device to plot. If not specified, the default is to make a change from baseline plot for all devices.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    \n",
    "    def get_visit_number(visit):\n",
    "        \"\"\"\n",
    "        Extracts the numeric part of the visit name for sorting.\n",
    "        Non-numeric visits are considered invalid and return None.\n",
    "        \"\"\"\n",
    "        import re\n",
    "        \n",
    "        match = re.match(r'^VISIT(\\d+)$', visit, re.IGNORECASE)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        elif visit.lower() == 'screening':\n",
    "            return 0\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def plot_device_data(df_filtered, endpoint, device):\n",
    "        \"\"\"\n",
    "        Helper function to plot the data for a specific device.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df_filtered : DataFrame\n",
    "            Filtered DataFrame containing the data for a specific device.\n",
    "        endpoint : str\n",
    "            The Digital_EP to plot (e.g., WASO, AHI, etc.).\n",
    "        device : str\n",
    "            The device to include in the plot title.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        None\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filter out invalid visits\n",
    "        df_filtered['visit_num'] = df_filtered['VISIT'].apply(get_visit_number)\n",
    "        df_filtered = df_filtered.dropna(subset=['visit_num'])\n",
    "\n",
    "        # Ensure visit_num is integer type\n",
    "        df_filtered['visit_num'] = df_filtered['visit_num'].astype(int)\n",
    "\n",
    "        # Determine the visit with the highest postfix\n",
    "        if not df_filtered['visit_num'].empty:\n",
    "            max_visit_row = df_filtered.loc[df_filtered['visit_num'].idxmax()]\n",
    "            comparison_visit = max_visit_row['VISIT']\n",
    "        else:\n",
    "            raise ValueError(\"No valid visits found.\")\n",
    "\n",
    "        # Filter the dataframe for the specified endpoint and remove rows with unknown cohort\n",
    "        df_filtered = df_filtered[df_filtered['COHORT'] != 'Unknown']\n",
    "\n",
    "        # Calculate the baseline value for each subject\n",
    "        df_baseline = df_filtered[df_filtered['VISIT'].str.lower() == 'screening'][['USUBJID', 'digital_EP_value']]\n",
    "        df_baseline = df_baseline.rename(columns={'digital_EP_value': 'digital_EP_baseline_value'})\n",
    "\n",
    "        # Merge baseline values with the original dataframe\n",
    "        df_merged = df_filtered.merge(df_baseline, on='USUBJID', how='left')\n",
    "\n",
    "        # Calculate the change from baseline for each subject at each visit\n",
    "        df_merged['calculated_change_from_baseline'] = df_merged['digital_EP_value'] - df_merged['digital_EP_baseline_value']\n",
    "\n",
    "        # Group by cohort and visit to calculate the mean, sem, and number of subjects\n",
    "        grouped = df_merged.groupby(['COHORT', 'VISIT'])\n",
    "        aggDf = grouped.agg(\n",
    "            mean=('calculated_change_from_baseline', 'mean'),\n",
    "            sem=('calculated_change_from_baseline', lambda x: x.std() / (len(x) ** 0.5)),\n",
    "            num_subjects=('calculated_change_from_baseline', 'count')\n",
    "        ).reset_index()\n",
    "\n",
    "        cohortList = aggDf['COHORT'].unique().tolist()\n",
    "\n",
    "        cohort2Color = {\n",
    "            cohortList[0]: 'black',\n",
    "            cohortList[1]: 'red'\n",
    "        }\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "        xticks = []\n",
    "        xlabels = []\n",
    "\n",
    "        for cohort in cohortList:\n",
    "\n",
    "            data = aggDf[aggDf['COHORT'] == cohort].reset_index(drop=True)\n",
    "\n",
    "            if data.empty:\n",
    "                continue\n",
    "\n",
    "            data['visit_num'] = data['VISIT'].apply(get_visit_number)\n",
    "            data = data.sort_values(by=['visit_num'])\n",
    "            visits = data['VISIT'].tolist()\n",
    "\n",
    "            x = data['visit_num'].tolist()\n",
    "            xticks += x\n",
    "            xlabels += visits\n",
    "\n",
    "            y = data['mean'].tolist()\n",
    "\n",
    "            yerr = data['sem'].tolist()\n",
    "\n",
    "            plt.errorbar(x, y, yerr=yerr, capsize=5, fmt='-o', color=cohort2Color[cohort], label=cohort, markersize=4)\n",
    "\n",
    "        xticks = list(set(xticks))\n",
    "        xticks.sort()\n",
    "\n",
    "        unique_xlabels = []\n",
    "        unique_xticks = []\n",
    "        for tick, label in zip(xticks, xlabels):\n",
    "            if tick not in unique_xticks:\n",
    "                unique_xticks.append(tick)\n",
    "                unique_xlabels.append(label)\n",
    "\n",
    "        plt.xticks(unique_xticks, unique_xlabels, rotation=45)\n",
    "        plt.legend(loc='best', prop={'size': 8})\n",
    "        title = f\"{device} {endpoint} Change from Baseline\"\n",
    "        plt.title(title, fontsize=10)\n",
    "        plt.xlabel('Visit', fontsize=10)\n",
    "        plt.ylabel(f'{endpoint} Change', fontsize=10)\n",
    "        plt.grid()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Filter by endpoint\n",
    "    df_filtered = df[df['digital_EP'] == endpoint]\n",
    "    \n",
    "    # If device is specified, plot for that device\n",
    "    if device:\n",
    "        df_filtered = df_filtered[df_filtered['DEVICE'].str.lower() == device.lower()]\n",
    "        plot_device_data(df_filtered, endpoint, device)\n",
    "    else:\n",
    "        # If no device is specified, plot for each device\n",
    "        for dev in df_filtered['DEVICE'].unique():\n",
    "            df_device = df_filtered[df_filtered['DEVICE'] == dev]\n",
    "            print(f\"Plotting for device: {dev}\")\n",
    "            plot_device_data(df_device, endpoint, dev)\n",
    "\n",
    "# Plot endpoint distribution for each device for each visit to have a general idea of device agreement\n",
    "\n",
    "@skill\n",
    "def plot_endpoint_distribution(df, endpoint, device1=None, device2=None, visit=None, bySeverityCategory=False):\n",
    "    \"\"\"\n",
    "    Plots histograms showing the distribution of a specified endpoint for each device and compares the means.\n",
    "    Optionally, plots the distribution by severity category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The original DataFrame containing the data.\n",
    "            'VISIT': Visit name (e.g. VISIT2)\n",
    "            'USUBJID': Unique subject ID\n",
    "            'digital_EP': Endpoint name (e.g. WASO, AHI, etc.)\n",
    "            'digital_EP_value': Endpoint value (some numeric value)\n",
    "            'digital_EP_severity_category': Severity category of the endpoint\n",
    "            'COHORT': Treatment group (e.g. Placebo/ Treatment)\n",
    "            'DEVICE': Device name (e.g. WatchPAT, PSG, etc.)\n",
    "    endpoint : str\n",
    "        The Digital_EP to plot (e.g., WASO, AHI, etc.).\n",
    "    device1 : str, optional\n",
    "        The first device to filter the data (e.g., WatchPAT, PSG).\n",
    "    device2 : str, optional\n",
    "        The second device to filter the data (e.g., WatchPAT, PSG).\n",
    "    visit : str, optional\n",
    "        The visit to filter the data (e.g., VISIT2). If not specified, the default is to plot for all visits where data for both devices is available.\n",
    "    bySeverityCategory : bool, optional\n",
    "        Whether to plot the distribution by severity category.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    from scipy.stats import ttest_ind\n",
    "\n",
    "    # Filter the DataFrame for the specified endpoint\n",
    "    df_filtered = df[df['digital_EP'] == endpoint]\n",
    "\n",
    "    # Filter by visit if specified\n",
    "    if visit:\n",
    "        df_filtered = df_filtered[df_filtered['VISIT'].str.lower() == visit.lower()]\n",
    "\n",
    "    # Ensure both devices are specified\n",
    "    if device1 is None or device2 is None:\n",
    "        devices = df['DEVICE'].unique()\n",
    "        if len(devices) < 2:\n",
    "            print(\"Not enough devices found in the data.\")\n",
    "            return\n",
    "        device1, device2 = devices[:2]\n",
    "\n",
    "    # Include only patients with data from both devices\n",
    "    subjects_with_both_devices = df_filtered[df_filtered['DEVICE'] == device1]['USUBJID'].isin(\n",
    "        df_filtered[df_filtered['DEVICE'] == device2]['USUBJID'])\n",
    "    common_subjects = df_filtered[df_filtered['DEVICE'] == device1][subjects_with_both_devices]['USUBJID']\n",
    "    df_filtered = df_filtered[df_filtered['USUBJID'].isin(common_subjects)]\n",
    "\n",
    "    if bySeverityCategory:\n",
    "        # Get the unique severity categories\n",
    "        severity_categories = df_filtered['digital_EP_severity_category'].unique()\n",
    "\n",
    "        # Create a plot for each severity category\n",
    "        for category in severity_categories:\n",
    "            category_data = df_filtered[df_filtered['digital_EP_severity_category'] == category]\n",
    "\n",
    "            # Create a histogram for each device within the severity category\n",
    "            plt.figure(figsize=(12, 8))\n",
    "\n",
    "            sns.histplot(data=category_data, x='digital_EP_value', hue='DEVICE', multiple='dodge', bins=20, kde=True)\n",
    "\n",
    "            subject_count = category_data['USUBJID'].nunique()\n",
    "            plt.title(f'{endpoint} Distribution by Device for Severity Category: {category} ({subject_count} subjects)')\n",
    "            plt.xlabel(f'{endpoint} Value')\n",
    "            plt.ylabel('Count')\n",
    "            plt.legend(title='Device')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        # Identify visits where data for both devices is available\n",
    "        visits = df_filtered['VISIT'].unique()\n",
    "        valid_visits = []\n",
    "        for v in visits:\n",
    "            visit_data = df_filtered[df_filtered['VISIT'].str.lower() == v.lower()]\n",
    "            if all(d in visit_data['DEVICE'].unique() for d in [device1, device2]):\n",
    "                valid_visits.append(v)\n",
    "        visits = valid_visits\n",
    "\n",
    "        statistics = []\n",
    "\n",
    "        # Create a plot for each visit\n",
    "        for visit in visits:\n",
    "            visit_data = df_filtered[df_filtered['VISIT'].str.lower() == visit.lower()]\n",
    "\n",
    "            device_data1 = visit_data[visit_data['DEVICE'].str.lower() == device1.lower()]\n",
    "            device_data2 = visit_data[visit_data['DEVICE'].str.lower() == device2.lower()]\n",
    "\n",
    "            if device_data1.empty or device_data2.empty:\n",
    "                print(f\"No data found for endpoint '{endpoint}' in visit '{visit}' for devices '{device1}' and '{device2}'.\")\n",
    "                continue\n",
    "\n",
    "            # Plot the histograms\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "            axs[0].hist(device_data1['digital_EP_value'], bins=20, alpha=0.7, color='blue', edgecolor='black', label=device1)\n",
    "            axs[0].set_title(f'{endpoint} values for {device1} in {visit}', fontsize=15)\n",
    "            axs[0].set_xlabel(f'{endpoint} Value', fontsize=12)\n",
    "            axs[0].set_ylabel('Frequency', fontsize=12)\n",
    "            axs[0].grid(axis='y', alpha=0.75)\n",
    "            axs[0].legend()\n",
    "\n",
    "            axs[1].hist(device_data2['digital_EP_value'], bins=20, alpha=0.7, color='green', edgecolor='black', label=device2)\n",
    "            axs[1].set_title(f'{endpoint} values for {device2} in {visit}', fontsize=15)\n",
    "            axs[1].set_xlabel(f'{endpoint} Value', fontsize=12)\n",
    "            axs[1].set_ylabel('Frequency', fontsize=12)\n",
    "            axs[1].grid(axis='y', alpha=0.75)\n",
    "            axs[1].legend()\n",
    "\n",
    "            plt.suptitle(f'Distribution of {endpoint} values in {visit}', fontsize=18)\n",
    "\n",
    "            # Calculate the means and perform a t-test to compare means\n",
    "            mean1 = device_data1['digital_EP_value'].mean()\n",
    "            mean2 = device_data2['digital_EP_value'].mean()\n",
    "            t_stat, p_value = ttest_ind(device_data1['digital_EP_value'], device_data2['digital_EP_value'])\n",
    "\n",
    "            # Generate conclusion based on p-value\n",
    "            if p_value < 0.05:\n",
    "                conclusion = f'There is a statistically significant difference between {device1} and {device2} in {visit} (p < 0.05).'\n",
    "            else:\n",
    "                conclusion = f'There is no statistically significant difference between {device1} and {device2} in {visit} (p >= 0.05).'\n",
    "\n",
    "            # Store statistics\n",
    "            statistics.append({\n",
    "                'Visit': visit,\n",
    "                f'{device1} Mean': mean1,\n",
    "                f'{device2} Mean': mean2,\n",
    "                'p-value': p_value,\n",
    "                'Conclusion': conclusion\n",
    "            })\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.show()\n",
    "\n",
    "        # Create a DataFrame from the statistics and display it\n",
    "        stats_df = pd.DataFrame(statistics)\n",
    "        print(stats_df)\n",
    "        for conclusion in stats_df['Conclusion']:\n",
    "            print(conclusion)\n",
    "\n",
    "# Plot endpoint correlation\n",
    "\n",
    "@skill\n",
    "def plot_correlation(df, endpoint1, endpoint2, device1=None, device2=None, bySeverityCategory=False):\n",
    "    \"\"\"\n",
    "    Plots scatter plots showing the correlation between two endpoints for each device.\n",
    "    Optionally, plots the correlation by severity category.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The original DataFrame containing the data.\n",
    "            'VISIT': Visit name (e.g. VISIT2)\n",
    "            'USUBJID': Unique subject ID\n",
    "            'digital_EP': Endpoint name (e.g. WASO, AHI, etc.)\n",
    "            'digital_EP_value': Endpoint value (some numeric value)\n",
    "            'digital_EP_severity_category': Severity category of the endpoint\n",
    "            'COHORT': Treatment group (e.g. Placebo/ Treatment)\n",
    "            'DEVICE': Device name (e.g. WatchPAT, PSG, etc.)\n",
    "    endpoint1 : str\n",
    "        The first endpoint to compare (e.g., WASO).\n",
    "    endpoint2 : str\n",
    "        The second endpoint to compare (e.g., AHI).\n",
    "    device1 : str, optional\n",
    "        The first device to filter the data (e.g., WatchPAT, PSG).\n",
    "    device2 : str, optional\n",
    "        The second device to filter the data (e.g., WatchPAT, PSG).\n",
    "    bySeverityCategory : bool, optional\n",
    "        Whether to plot the correlation by severity category.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    from scipy.stats import linregress, spearmanr, pearsonr\n",
    "\n",
    "    # Filter the DataFrame for the specified endpoints\n",
    "    if endpoint1 == endpoint2:\n",
    "        \n",
    "        devices = df['DEVICE'].unique()\n",
    "        device1, device2 = devices[:2]\n",
    "        \n",
    "        df1 = df[(df['digital_EP'] == endpoint1) & (df['DEVICE'] == device1)][['USUBJID', 'VISIT', 'digital_EP_value', 'digital_EP_severity_category', 'DEVICE']].rename(columns={'digital_EP_value': f'digital_EP_value_{device1}'})\n",
    "        df2 = df[(df['digital_EP'] == endpoint1) & (df['DEVICE'] == device2)][['USUBJID', 'VISIT', 'digital_EP_value', 'digital_EP_severity_category', 'DEVICE']].rename(columns={'digital_EP_value': f'digital_EP_value_{device2}'})\n",
    "    else:\n",
    "        df1 = df[df['digital_EP'] == endpoint1][['USUBJID', 'VISIT', 'digital_EP_value', 'digital_EP_severity_category', 'DEVICE']].rename(columns={'digital_EP_value': f'{endpoint1}_value'})\n",
    "        df2 = df[df['digital_EP'] == endpoint2][['USUBJID', 'VISIT', 'digital_EP_value', 'digital_EP_severity_category', 'DEVICE']].rename(columns={'digital_EP_value': f'{endpoint2}_value'})\n",
    "\n",
    "    # Merge the two DataFrames on the subject ID and visit\n",
    "    df_merged = pd.merge(df1, df2, on=['USUBJID', 'VISIT', 'digital_EP_severity_category'], suffixes=(f'_{device1}', f'_{device2}'))\n",
    "\n",
    "    # Check if there is data to plot\n",
    "    if df_merged.empty:\n",
    "        print(\"Please specify valid endpoints to compare. If there is one endpoint, please specify the devices to compare. You can also specify whether to plot by severity category.\")\n",
    "        return \"No overlapping data to plot.\"\n",
    "\n",
    "    def create_plot(x, y, hue, title, xlabel, ylabel):\n",
    "        # Calculate the correlation coefficients and line of best fit\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "        line = slope * x + intercept\n",
    "        spearman_corr, spearman_p_value = spearmanr(x, y)\n",
    "        pearson_corr, pearson_p_value = pearsonr(x, y)\n",
    "\n",
    "        # Create the scatter plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x=x, y=y, hue=hue, palette='deep')\n",
    "        plt.plot(x, line, color='red', label=f'Line of Best Fit: y={slope:.2f}x+{intercept:.2f}')\n",
    "        plt.title(f'{title}\\n'\n",
    "                  f'Spearman Correlation: {spearman_corr:.2f}\\n       '\n",
    "                  f'Pearson Correlation: {pearson_corr:.2f}\\n p-value: {pearson_p_value:.4f}')\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if bySeverityCategory:\n",
    "        # Get the unique severity categories\n",
    "        severity_categories = df_merged['digital_EP_severity_category'].unique()\n",
    "\n",
    "        # Create a plot for each severity category\n",
    "        for category in severity_categories:\n",
    "            category_data = df_merged[df_merged['digital_EP_severity_category'] == category]\n",
    "\n",
    "            if endpoint1 == endpoint2:\n",
    "                x = category_data[f'digital_EP_value_{device1}']\n",
    "                y = category_data[f'digital_EP_value_{device2}']\n",
    "            else:\n",
    "                x = category_data[f'{endpoint1}_value']\n",
    "                y = category_data[f'{endpoint2}_value']\n",
    "\n",
    "            create_plot(x, y, category_data[f'DEVICE_{device1}'],\n",
    "                        f'{device1} {endpoint1} vs {device2} {endpoint2} Correlation\\nSeverity Category: {category}',\n",
    "                        f'{device1} {endpoint1} Value', f'{device2} {endpoint2} Value')\n",
    "    else:\n",
    "        if endpoint1 == endpoint2:\n",
    "            x = df_merged[f'digital_EP_value_{device1}']\n",
    "            y = df_merged[f'digital_EP_value_{device2}']\n",
    "        else:\n",
    "            x = df_merged[f'{endpoint1}_value']\n",
    "            y = df_merged[f'{endpoint2}_value']\n",
    "\n",
    "        create_plot(x, y, df_merged[f'DEVICE_{device1}'],\n",
    "                    f'{device1} {endpoint1} vs {device2} {endpoint2} Correlation',\n",
    "                    f'{device1} {endpoint1} Value', f'{device2} {endpoint2} Value')\n",
    "\n",
    "# Plot confusion matrix by severity category\n",
    "\n",
    "@skill\n",
    "def severity_category_confusion_matrix(df, endpoint, device=None, visit1='Screening', visit2=None):\n",
    "    \"\"\"\n",
    "    Generates confusion matrices for severity categories of an endpoint between two visits for each treatment cohort.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The original DataFrame containing the data.\n",
    "            'VISIT': Visit name (e.g. VISIT2)\n",
    "            'USUBJID': Unique subject ID\n",
    "            'digital_EP': Endpoint name (e.g. WASO, AHI, etc.)\n",
    "            'digital_EP_severity_category': Severity category of the endpoint\n",
    "            'COHORT': Treatment group (e.g. Placebo/ Treatment)\n",
    "            'DEVICE': Device name (e.g. WatchPAT, PSG, etc.)\n",
    "    endpoint : str\n",
    "        The endpoint to analyze (e.g., WASO, AHI, etc.).\n",
    "    device : str, optional\n",
    "        The device to filter the data (e.g., WatchPAT, PSG). If not specified, a random device is chosen.\n",
    "    visit1 : str, optional\n",
    "        The first visit to compare (default is 'Screening').\n",
    "    visit2 : str, optional\n",
    "        The second visit to compare (default is the latest valid visit).\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    if visit2 is None:\n",
    "        # Get the latest valid visit\n",
    "        visits = df['VISIT'].str.extract(r'(\\d+)', expand=False).dropna().astype(int)\n",
    "        latest_visit_num = visits.max()\n",
    "        visit2 = f'VISIT{latest_visit_num}'\n",
    "    \n",
    "    # Filter the DataFrame for the specified endpoint\n",
    "    df_filtered = df[df['digital_EP'] == endpoint]\n",
    "    \n",
    "    if device is None:\n",
    "        device = np.random.choice(df_filtered['DEVICE'].unique())\n",
    "    \n",
    "    df_filtered = df_filtered[df_filtered['DEVICE'] == device]\n",
    "    \n",
    "    # Get the unique treatment cohorts\n",
    "    cohorts = df_filtered['COHORT'].unique()\n",
    "    \n",
    "    # Define the order of severity categories\n",
    "    severity_order = ['Severe', 'Moderate', 'Mild', 'No']\n",
    "    \n",
    "    for cohort in cohorts:\n",
    "        df_cohort = df_filtered[df_filtered['COHORT'] == cohort]\n",
    "        \n",
    "        # Filter data for visit1 and visit2\n",
    "        df_visit1 = df_cohort[df_cohort['VISIT'].str.lower() == visit1.lower()][['USUBJID', 'digital_EP_severity_category']]\n",
    "        df_visit2 = df_cohort[df_cohort['VISIT'].str.lower() == visit2.lower()][['USUBJID', 'digital_EP_severity_category']]\n",
    "        \n",
    "        # Rename columns to avoid confusion when merging\n",
    "        df_visit1 = df_visit1.rename(columns={'digital_EP_severity_category': f'severity_category_{visit1}'})\n",
    "        df_visit2 = df_visit2.rename(columns={'digital_EP_severity_category': f'severity_category_{visit2}'})\n",
    "        \n",
    "        # Merge the two visits on USUBJID\n",
    "        df_merged = pd.merge(df_visit1, df_visit2, on='USUBJID')\n",
    "        \n",
    "        if df_merged.empty:\n",
    "            print(f\"No overlapping data between {visit1} and {visit2} for cohort {cohort}.\")\n",
    "            continue\n",
    "\n",
    "        # Generate the confusion matrix\n",
    "        y_true = pd.Categorical(df_merged[f'severity_category_{visit1}'], categories=severity_order, ordered=True)\n",
    "        y_pred = pd.Categorical(df_merged[f'severity_category_{visit2}'], categories=severity_order, ordered=True)\n",
    "        \n",
    "        cm = pd.crosstab(y_true, y_pred, rownames=[f'Severity Category at {visit1}'], colnames=[f'Severity Category at {visit2}'], dropna=False)\n",
    "        \n",
    "        if cm.empty:\n",
    "            print(f\"No data to plot for cohort {cohort}.\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate percentages\n",
    "        cm_percentage = cm.div(cm.sum(axis=1), axis=0) * 100\n",
    "        \n",
    "        # Create annotations with counts and percentages\n",
    "        annot = cm.astype(str) + \"\\n\" + cm_percentage.round(2).astype(str) + '%'\n",
    "\n",
    "        # Plot the confusion matrix\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=severity_order, yticklabels=severity_order, cbar=False)\n",
    "        ax = sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', xticklabels=severity_order, yticklabels=severity_order, cbar=False)\n",
    "        plt.xlabel(f'Severity Category at {visit2}', )\n",
    "        plt.ylabel(f'Severity Category at {visit1}')\n",
    "        plt.title(f'Confusion Matrix of Severity Categories for {endpoint}\\nDevice: {device}, Cohort: {cohort}')\n",
    "        ax.xaxis.set_ticks_position('top')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Categorized Strip Plot\n",
    "@skill\n",
    "def categorized_strip_plot(df, endpoint, gold_standard_device, visit=None):\n",
    "    \"\"\"\n",
    "    Creates categorized strip plots for each device to visualize incorrect classifications compared to a gold standard device.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The original DataFrame containing the data.\n",
    "            'VISIT': Visit name (e.g. VISIT2)\n",
    "            'USUBJID': Unique subject ID\n",
    "            'digital_EP': Endpoint name (e.g. WASO, AHI, etc.)\n",
    "            'digital_EP_value': Endpoint value (some numeric value)\n",
    "            'digital_EP_severity_category': Severity category of the endpoint\n",
    "            'COHORT': Treatment group (e.g. Placebo/ Treatment)\n",
    "            'DEVICE': Device name (e.g. WatchPAT, PSG, etc.)\n",
    "    endpoint : str\n",
    "        The endpoint to analyze (e.g., WASO, AHI, etc.).\n",
    "    gold_standard_device : str\n",
    "        The device to be used as the gold standard for classification (e.g., PSG).\n",
    "    visit : str, optional\n",
    "        The visit to filter the data (default is to use all visits).\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Define severity order\n",
    "    severity_order = ['No', 'Mild', 'Moderate', 'Severe']\n",
    "    \n",
    "    # Filter the DataFrame for the specified endpoint and visit\n",
    "    df_filtered = df[df['digital_EP'] == endpoint]\n",
    "    \n",
    "    if visit:\n",
    "        df_filtered = df_filtered[df_filtered['VISIT'].str.lower() == visit.lower()]\n",
    "\n",
    "    # Ensure device names are handled case-insensitively\n",
    "    df_filtered['DEVICE'] = df_filtered['DEVICE'].str.lower()\n",
    "    gold_standard_device = gold_standard_device.lower()\n",
    "\n",
    "    # Create a pivot table to compare devices\n",
    "    df_pivot = df_filtered.pivot_table(index='USUBJID', columns='DEVICE', values='digital_EP_severity_category', aggfunc='first')\n",
    "    \n",
    "    # Check if the gold standard device is in the DataFrame\n",
    "    if gold_standard_device not in df_pivot.columns:\n",
    "        print(f\"The gold standard device '{gold_standard_device}' is not in the DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    # Iterate over devices to create plots\n",
    "    for device in df_pivot.columns:\n",
    "        if device == gold_standard_device:\n",
    "            continue\n",
    "        \n",
    "        # Create a DataFrame for plotting\n",
    "        plot_df = df_pivot[[gold_standard_device, device]].dropna().reset_index()\n",
    "        plot_df['Severity'] = plot_df[gold_standard_device]\n",
    "        \n",
    "        # Create the strip plot for the gold standard device\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.stripplot(x=gold_standard_device, y='USUBJID', data=plot_df, order=severity_order, palette='deep', size=8, alpha=0.6, jitter=False)\n",
    "        \n",
    "        # Create the strip plot for the current device, using hue to differentiate severity categories\n",
    "        sns.stripplot(x=device, y='USUBJID', data=plot_df, order=severity_order, hue='Severity', size=6, alpha=0.6, dodge=True, palette='deep', jitter=True)\n",
    "        \n",
    "        plt.xlabel(f'True Severity Category ({gold_standard_device.upper()} {endpoint})')\n",
    "        plt.ylabel('Subjects')\n",
    "        plt.title(f'Misclassification for {device.upper()} {endpoint} compared to {gold_standard_device.upper()} {endpoint}, Visit: {visit if visit else \"All\"}')\n",
    "        plt.legend(title=f'{device.upper()} {endpoint} Severity Category', bbox_to_anchor=(1.05, 1), loc='upper left', labels=severity_order, handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=c, markersize=10) for c in sns.color_palette('deep', len(severity_order))])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "agent = Agent(df, vectorstore=vector_store, config=config, description=description)\n",
    "agent.add_skills(bland_altman_plot, change_from_baseline_plot, plot_endpoint_distribution, plot_correlation, severity_category_confusion_matrix, categorized_strip_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instructions Training\n",
    "# # Correctly format the training document\n",
    "# training_docs = [\n",
    "#     \"For each pandasai skills function where any parameter is missing. Ask the user a clarifying question whether they want to use the default plot or specify a parameter. For example, if the use didn't specify to set the bySeverityCategory to True/ False, ask the user: Would you like to plot by severity category?\", \n",
    "#     \"Never return an input error, always ask the user to clarify function call parameters if mandatory ones are missing\"\n",
    "# ]\n",
    "\n",
    "# # Train the agent with the formatted documents\n",
    "# agent.train(docs=training_docs)\n",
    "\n",
    "\n",
    "# ## Q/A train\n",
    "# # Train for bland_altman_plot\n",
    "# query = \"Plot a bland altman plot comparing AHI for the devices\"\n",
    "# query2 = \"Generate the Bland-Altman plot for ahi using watchpat and psg devices\"\n",
    "# query3 = \"Generate the Bland-Altman plot for AHI for all severity categories\"\n",
    "# response = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "\n",
    "#     bland_altman_plot(df, endpoint1='AHI', endpoint2='AHI', device1='WatchPAT', device2='PSG', bySeverityCategory=False)\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "# response3 = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "\n",
    "#     bland_altman_plot(df, endpoint1='AHI', endpoint2='AHI', device1='WatchPAT', device2='PSG', bySeverityCategory=True)\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "\n",
    "# agent.train(queries=[query, query2, query3], codes=[response, response, response3])\n",
    "\n",
    "# #Train for change from baseline\n",
    "# query = \"Plot the change from baseline for AHI\"\n",
    "# query2 = \"Plot the AHI change from baseline for all devices\"\n",
    "# response = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "    \n",
    "#     change_from_baseline_plot(df, endpoint='AHI', device=None)\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "\n",
    "# query3 = \"Plot the PSG AHI change from baseline\"\n",
    "# response3 = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "    \n",
    "#     change_from_baseline_plot(df, endpoint='AHI', device='PSG')\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "\n",
    "# agent.train(queries=[query, query2], codes=[response, response])\n",
    "\n",
    "# # Train for plotting endpoint distribution\n",
    "# query = \"Plot endpoint distribution for each device for each visit to have a general idea of device agreement\"\n",
    "# query2 = \"Plot AHI distribution by severity category\"\n",
    "# response = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "    \n",
    "#     plot_endpoint_distribution(df, 'AHI', device1=None, device2=None, visit=None, bySeverityCategory = False)\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "# response2 = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "    \n",
    "#     plot_endpoint_distribution(df, 'AHI', device1=None, device2=None, visit=None, bySeverityCategory = True)\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "# agent.train(queries=[query, query2], codes=[response, response2]) \n",
    "\n",
    "# # Train for ploting correlation between two endpoints or devices\n",
    "# query = \"Plot the correlation between the two devices for AHI\"\n",
    "# query2 = \"Plot AHI correlation comparing the devices\"\n",
    "# response = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "    \n",
    "#     plot_correlation(df, endpoint1='AHI', endpoint2='AHI', device1='PSG', device2='WatchPAT', bySeverityCategory=False)\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "# agent.train(queries=[query, query2], codes=[response, response]) \n",
    "\n",
    "# # Train for plotting severity category confusion matrix\n",
    "# query = \"Plot a confusion matrix visualizing how the severity category changes over time for AHI\"\n",
    "# query2 = \"Plot AHI severity confusion matrix\"\n",
    "# response = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "    \n",
    "#     severity_category_confusion_matrix(df, endpoint, device=None, visit1='Screening', visit2=None)\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "# agent.train(queries=[query, query2], codes=[response, response]) \n",
    "\n",
    "# # Train for creating a categorized strip plot\n",
    "# query = \"Create a categorized strip plot for AHI where PSG is the gold standard\"\n",
    "# response = \"\"\"\n",
    "# def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "#     df = dfs[0]\n",
    "    \n",
    "#     categorized_strip_plot(df, endpoint='AHI', gold_standard_device='PSG', visit=None)\n",
    "#     return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "# \"\"\"\n",
    "# agent.train(queries=[query], codes=[response]) \n",
    "\n",
    "# # The model will use the information provided in the training to generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions Training\n",
    "# Correctly format the training document\n",
    "training_docs = [\n",
    "    \"For each pandasai skills function where any parameter is missing. Ask the user a clarifying question whether they want to use the default plot or specify a parameter. For example, if the use didn't specify to set the bySeverityCategory to True/ False, ask the user: Would you like to plot by severity category?\", \n",
    "    \"Never return an input error or an empty graph, let the user know if their desired plot cannot be done using the custom function calls\", \n",
    "    \"always ask the user to clarify important function call parameters\"\n",
    "]\n",
    "\n",
    "# Train the agent with the formatted documents\n",
    "agent.train(docs=training_docs)\n",
    "\n",
    "## Q/A train\n",
    "# Train for bland_altman_plot\n",
    "query = \"Plot a bland altman plot comparing AHI for the devices\"\n",
    "query2 = \"Generate the Bland-Altman plot for ahi using watchpat and psg devices\"\n",
    "query3 = \"Generate the Bland-Altman plot for AHI for all severity categories\"\n",
    "response = \"\"\"\n",
    "def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "    df = dfs[0]\n",
    "\n",
    "    response = bland_altman_plot(df, endpoint1='AHI', endpoint2='AHI', device1='WatchPAT', device2='PSG', bySeverityCategory=False)\n",
    "    if response == \"error\":\n",
    "        return { \"type\": \"text\", \"value\": response}\n",
    "    return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "\"\"\"\n",
    "response3 = \"\"\"\n",
    "def analyze_data(dfs: list[pd.DataFrame]) -> dict:\n",
    "    df = dfs[0]\n",
    "\n",
    "    response = bland_altman_plot(df, endpoint1='AHI', endpoint2='AHI', device1='WatchPAT', device2='PSG', bySeverityCategory=True)\n",
    "    if response == \"error\":\n",
    "        return { \"type\": \"text\", \"value\": response}\n",
    "    return { \"type\": \"plot\", \"value\": \"temp_chart.png\"}\n",
    "\"\"\"\n",
    "\n",
    "# Attempt to train clarifying questions\n",
    "query4 = \"Plot a bland altman plot\"\n",
    "query5 = \"Tell me what I need to specify for you to plot a bland altman plot\"\n",
    "query6 = \"How do I plot a bland altman plot?\"\n",
    "response4 = \"\"\"\n",
    "To plot a bland altman plot, you need to specify the endpoints or devices to compare. You can also plot by the severity category.\n",
    "    For example:\n",
    "    1. Plot a bland altman plot comparing AHI and pAHI.\n",
    "    2. Plot a bland altman plot for AHI for the devices by severity category.\n",
    "\"\"\"\n",
    "response5 = \"\"\"\n",
    "To plot a Bland-Altman plot, please provide the following details:\n",
    "1. Endpoints to compare (e.g., AHI vs. pAHI).\n",
    "2. Devices used for the measurement (e.g., WatchPAT and PSG).\n",
    "3. Whether to categorize by severity.\n",
    "\"\"\"\n",
    "response6 = \"\"\"\n",
    "To plot a Bland-Altman plot, you need to specify:\n",
    "1. Endpoints to compare.\n",
    "2. Devices used for measurements.\n",
    "3. Whether to categorize by severity.\n",
    "For example, \"Plot a Bland-Altman plot comparing AHI for WatchPAT and PSG by severity category.\"\n",
    "\"\"\"\n",
    "\n",
    "agent.train(queries=[query, query2, query3, query4, query5, query6], codes=[response, response, response3, response4, response5, response6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test prompts which worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bland_altman_plot_test_prompts = [\"Plot a bland altman plot comparing AHI for both devices\"]\n",
    "change_from_baseline_plot_test_prompts = [\"Plot the AHI change from baseline for all devices\", \"Plot the AHI change from baseline\", \"Plot the AHI change from baseline for WatchPAT\"]\n",
    "endpoint_distribution_plot_test_prompts = [\"Plot the AHI distribution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/L075945/Library/CloudStorage/OneDrive-EliLillyandCompany/Desktop/test_pandasai_skills/.venv/lib/python3.11/site-packages/pandasai/pipelines/chat/generate_chat_pipeline.py\", line 283, in run\n",
      "    output = (self.code_generation_pipeline | self.code_execution_pipeline).run(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/L075945/Library/CloudStorage/OneDrive-EliLillyandCompany/Desktop/test_pandasai_skills/.venv/lib/python3.11/site-packages/pandasai/pipelines/pipeline.py\", line 137, in run\n",
      "    raise e\n",
      "  File \"/Users/L075945/Library/CloudStorage/OneDrive-EliLillyandCompany/Desktop/test_pandasai_skills/.venv/lib/python3.11/site-packages/pandasai/pipelines/pipeline.py\", line 101, in run\n",
      "    step_output = logic.execute(\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"/Users/L075945/Library/CloudStorage/OneDrive-EliLillyandCompany/Desktop/test_pandasai_skills/.venv/lib/python3.11/site-packages/pandasai/pipelines/chat/code_generator.py\", line 33, in execute\n",
      "    code = pipeline_context.config.llm.generate_code(input, pipeline_context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/L075945/Library/CloudStorage/OneDrive-EliLillyandCompany/Desktop/test_pandasai_skills/.venv/lib/python3.11/site-packages/pandasai/llm/base.py\", line 197, in generate_code\n",
      "    return self._extract_code(response)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/L075945/Library/CloudStorage/OneDrive-EliLillyandCompany/Desktop/test_pandasai_skills/.venv/lib/python3.11/site-packages/pandasai/llm/base.py\", line 122, in _extract_code\n",
      "    raise NoCodeFoundError(\"No code found in the response\")\n",
      "pandasai.exceptions.NoCodeFoundError: No code found in the response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want the weather for a specific city in Indiana or the general weather for the entire state?\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What's the weather today in Indiana\"\n",
    "try:\n",
    "    response = agent.chat(user_query)\n",
    "    if response[\"type\"] == \"error\":\n",
    "        questions = agent.clarification_questions(user_query)\n",
    "        print(questions[0])\n",
    "except Exception as e:\n",
    "    questions = agent.clarification_questions(user_query)\n",
    "    print(questions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(agent.last_code_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is Unfortunately, I was not able to answer your question, because of the following error:\n",
      "\n",
      "name 'input' is not defined\n",
      "\n",
      "The explanation is The code I created is essentially a set of instructions for the computer to create a specific type of graph called a Bland-Altman plot. This plot is used to compare two different methods of measuring the same thing, to see how similar or different they are.\n",
      "\n",
      "First, the code asks the user to provide the two things they want to compare. These could be two different devices or methods used to measure the same thing. The user can also choose to compare the results by severity category, which could be useful in medical or scientific research.\n",
      "\n",
      "Once the user has provided this information, the code then creates the Bland-Altman plot. It does this by calculating the average and difference of the measurements from the two methods, and then plotting these on a graph. The average is plotted on the x-axis and the difference on the y-axis.\n",
      "\n",
      "Finally, the code saves the plot as an image file on the user's computer. This allows the user to easily view the plot and share it with others.\n"
     ]
    }
   ],
   "source": [
    "# for questions cannot be answered, you can ask for explanation\n",
    "explanation = agent.explain()\n",
    "\n",
    "print(\"The answer is\", response)\n",
    "print(\"The explanation is\", explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
